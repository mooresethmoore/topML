{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage.morphology import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "from ase.io import cube\n",
    "from ase.io import cif\n",
    "import h5py\n",
    "import pickle\n",
    "import io\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from scipy.spatial import Delaunay\n",
    "import plotly\n",
    "from plotly.graph_objs import graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatgen.core as mg\n",
    "from pymatgen.io.cif import CifWriter\n",
    "from pymatgen.io.cif import CifFile\n",
    "from pymatgen.core.structure import Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi,gudhi.hera,gudhi.wasserstein,persim\n",
    "import ripserplusplus as rpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inDir=\"Z:/data/diverse_metals\"\n",
    "os.chdir(inDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropUnnamed(df):\n",
    "    return df.loc[:,~df.columns.str.match(\"Unnamed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postR=pd.read_csv(\"post_comb_vsa-CO2-repeat.csv\",index_col=0)\n",
    "\n",
    "postR.index=[i[:i.find(\"_repeat\")] for i in postR.index]\n",
    "\n",
    "overall=pd.read_csv(\"overall_process.csv\",index_col=1)\n",
    "overall=dropUnnamed(overall)\n",
    "\n",
    "overall.index=[i[:i.find(\"_repeat\")] for i in overall.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False in {i.find(\"_repeat\")!=-1 for i in overall.index} # every name contains repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datG=pd.read_csv(\"post-combustion-vsa-2-clean.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datGIndex=datG.index\n",
    "\n",
    "len(set(datGIndex) & {i[:i.find(\"_repeat\")] for i in postR.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapCO2=set([i[:i.find(\"_repeat\")] for i in os.listdir(f\"{inDir}/for_seth/most_probable_sites\")]) &set(datGIndex) \n",
    "overlapCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(overlapCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB0-m1_o2_o5_f0_pcu.cif\"\n",
    "#viz_mof_cif_v2(f\"{inDir}/cifs/{fName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#struct=CifFile.from_file(f\"{inDir}/cifs/{fName}\")\n",
    "struct=Structure.from_file(f\"{inDir}/cifs/{fName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct.distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rppdgm=rpp.run(\"--format distance --dim 2\",struct.distance_matrix)\n",
    "rppdgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npdgm=[np.array([[float(rppdgm[b][k][0]),float(rppdgm[b][k][1])] for k in range(len(rppdgm[b]))])for b in rppdgm.keys()]\n",
    "persim.plot_diagrams(npdgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.io.cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forking portions from Xiaoli's plotlyMOF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_cif_lattice_param(fname):\n",
    "    cif_str = None\n",
    "    with io.open(fname, \"r\", newline=\"\\n\") as cif:\n",
    "        cif_str = cif.read().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "    cif_list = cif_str.split(\"loop_\")\n",
    "    for cif_section in cif_list:\n",
    "        if \"_cell_length_a\" in cif_section:\n",
    "            a = float(cif_section.split(\"_cell_length_a\")[1].split(\"\\n\")[0])\n",
    "            b = float(cif_section.split(\"_cell_length_b\")[1].split(\"\\n\")[0])\n",
    "            c = float(cif_section.split(\"_cell_length_c\")[1].split(\"\\n\")[0])\n",
    "\n",
    "            alpha = float(cif_section.split(\"_cell_angle_alpha\")[1].split(\"\\n\")[0])\n",
    "            beta = float(cif_section.split(\"_cell_angle_beta\")[1].split(\"\\n\")[0])\n",
    "            gamma = float(cif_section.split(\"_cell_angle_gamma\")[1].split(\"\\n\")[0])\n",
    "            break\n",
    "    return a, b, c, alpha, beta, gamma\n",
    "\n",
    "def read_cif_xyz(fname):\n",
    "    cif_str = None\n",
    "    with io.open(fname, \"r\", newline=\"\\n\") as cif:\n",
    "        cif_str = cif.read().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    cif_list = cif_str.split(\"loop_\")\n",
    "    for cif_section in cif_list:\n",
    "        if \"_atom_site_fract_x\" in cif_section:\n",
    "            #atom_lines = cif_section.split(\"\\n\")\n",
    "            columns = list(re.findall(r\".*_atom_.*\\n\", cif_section))\n",
    "            df_str = cif_section.replace(\"\".join(columns), \"\").strip()\n",
    "            columns = [x.strip() for x in columns]\n",
    "            return pd.read_csv(io.StringIO(df_str), names=columns, sep=r\"\\s+\")\n",
    "    return None\n",
    "\n",
    "def read_cif_bond(fname):\n",
    "    cif_str = None\n",
    "    with io.open(fname, \"r\", newline=\"\\n\") as cif:\n",
    "        cif_str = cif.read().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    cif_list = cif_str.split(\"loop_\")\n",
    "    for cif_section in cif_list:\n",
    "        if \"_geom_bond_atom_site_label_1\" in cif_section:\n",
    "            #bond_lines = cif_section.split(\"\\n\")\n",
    "            columns = list(re.findall(r\".*_geom_.*\\n\", cif_section))\n",
    "            df_str = cif_section.replace(\"\".join(columns), \"\").strip()\n",
    "            columns = [x.strip() for x in columns]\n",
    "            return pd.read_csv(io.StringIO(df_str), names=columns, sep=r\"\\s+\")\n",
    "    return None\n",
    "\n",
    "def pairwise_distance_pbc(df1, df2, M):\n",
    "    needed_cols = [\"_atom_site_label\", \"_atom_site_type_symbol\",\n",
    "                   \"_atom_site_fract_x\", \"_atom_site_fract_y\", \"_atom_site_fract_z\"]\n",
    "    xyz_cols = [\"_atom_site_fract_x\", \"_atom_site_fract_y\", \"_atom_site_fract_z\"]\n",
    "    site_col = \"_atom_site_label\"\n",
    "    np1_expand = df1.loc[:, needed_cols].to_numpy().repeat(len(df2), axis=0)\n",
    "    np2_expand = np.tile(df2.loc[:, needed_cols].to_numpy(), (len(df1), 1))\n",
    "    df1_expand = pd.DataFrame(np1_expand, columns=needed_cols)\n",
    "    df2_expand = pd.DataFrame(np2_expand, columns=needed_cols)\n",
    "    dxdydz = df1_expand.loc[:, xyz_cols] - df2_expand.loc[:, xyz_cols]\n",
    "    dxdydz[dxdydz>0.5] -= 1\n",
    "    dxdydz[dxdydz<-0.5] += 1\n",
    "    dist2 = ((dxdydz @ M) * (dxdydz @ M)).sum(axis=1)\n",
    "    sub_df = pd.DataFrame(np.array([df1_expand.loc[:, site_col].to_list(),\n",
    "                                    df2_expand.loc[:, site_col].to_list(),\n",
    "                                    dist2.to_list()]).T,\n",
    "                          columns=[\"A\", \"B\", \"dist2\"]).astype({\"A\": str,\n",
    "                                                               \"B\": str,\n",
    "                                                               \"dist2\": float})\n",
    "    sub_df = sub_df.sort_values(by=\"dist2\").reset_index(drop=True)\n",
    "    return sub_df\n",
    "\n",
    "def lat_param2vec(lat_param):\n",
    "    a, b, c, alpha, beta, gamma = lat_param\n",
    "    alpha_rad = alpha * np.pi / 180\n",
    "    beta_rad = beta * np.pi / 180\n",
    "    gamma_rad = gamma * np.pi / 180\n",
    "    n2 = (np.cos(alpha_rad)-np.cos(gamma_rad)*np.cos(beta_rad))/np.sin(gamma_rad)\n",
    "    M  = np.array([[a,                   0,                   0],\n",
    "                   [b*np.cos(gamma_rad), b*np.sin(gamma_rad), 0],\n",
    "                   [c*np.cos(beta_rad),  c*n2,                c*np.sqrt(np.sin(beta_rad)**2-n2**2)]])\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_mof_cif_v2(cif_name, fract_disp=np.array([0, 0, 0]), showbackground=False, tol=0.01, bond_dist_sqr_threshold=6):\n",
    "    table_dict = {}\n",
    "    # https://github.com/Bowserinator/Periodic-Table-JSON\n",
    "    with io.open(\"PeriodicTableJSON.json\", \"rb\") as f:\n",
    "        table_dict = json.load(f)\n",
    "    element_df = pd.DataFrame(table_dict[\"elements\"])\n",
    "    element_df[\"cpk-hex\"] = element_df[\"cpk-hex\"].fillna(\"0000ff\")\n",
    "    symbol2color = dict(zip(element_df[\"symbol\"], element_df[\"cpk-hex\"]))\n",
    "    symbol2color[\"X\"] = \"0000ff\"\n",
    "    idx2symbol = dict(zip(element_df[\"number\"], element_df[\"symbol\"]))\n",
    "    idx2symbol[0] = \"X\"\n",
    "\n",
    "    _cif_name = cif_name\n",
    "    #cif_str = None\n",
    "    with io.open(cif_name, \"r\", newline=\"\\n\") as cif:\n",
    "        cif_str = cif.read().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    cif_list = cif_str.split(\"loop_\")\n",
    "    for cif_section in cif_list:\n",
    "        if \"_symmetry_equiv_pos_as_xyz\" in cif_section:\n",
    "            if len(cif_section.split(\"_cell_\")[0].split(\"_symmetry_equiv_pos_as_xyz\")[1].strip().split(\"\\n\")) > 1:\n",
    "                cif_name = cif_name.replace(\".cif\", \"_P1.cif\")\n",
    "                CifWriter(mg.Structure.from_str(cif_str, fmt=\"cif\"), refine_struct=False).write_file(cif_name)\n",
    "\n",
    "\n",
    "    M = lat_param2vec(read_cif_lattice_param(cif_name))\n",
    "    A, B, C = M\n",
    "    atom_df = read_cif_xyz(cif_name)\n",
    "    bond_df = read_cif_bond(cif_name)\n",
    "\n",
    "    #bond_df = None\n",
    "    Natoms = len(atom_df)\n",
    "    atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                    \"_atom_site_fract_y\",\n",
    "                    \"_atom_site_fract_z\"]] = (atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                              \"_atom_site_fract_y\",\n",
    "                                                              \"_atom_site_fract_z\"]].values + fract_disp) % 1# - np.array([0.5, 0.5, 0.5])) % 1\n",
    "    atom_df[\"x\"] = None\n",
    "    atom_df[\"y\"] = None\n",
    "    atom_df[\"z\"] = None\n",
    "    atom_df[\"_atom_site_label_prefix\"] = atom_df[\"_atom_site_label\"].apply(lambda x: re.findall(r\"[A-Z]*[a-z]*\", x)[0])\n",
    "    atom_df[\"_atom_site_label_postfix\"] = atom_df[\"_atom_site_label\"].apply(lambda x: re.findall(r\"[0-9]+\", x)[0])\n",
    "\n",
    "\n",
    "    error_atom_index = atom_df[atom_df[\"_atom_site_label_prefix\"]!=atom_df[\"_atom_site_type_symbol\"]].index\n",
    "    atom_df.loc[error_atom_index, \"_atom_site_label\"] = atom_df.loc[error_atom_index, \"_atom_site_type_symbol\"].astype(str) + \\\n",
    "                                                        atom_df.loc[error_atom_index, \"_atom_site_label_postfix\"].astype(str)\n",
    "\n",
    "    unique_elements = sorted(atom_df[\"_atom_site_type_symbol\"].unique().tolist())\n",
    "    natoms_per_element = {}\n",
    "    atom_idx_offset = np.zeros(Natoms, dtype=int)\n",
    "    atom_df.loc[:, \"_atom_site_label_save\"] = atom_df.loc[:, \"_atom_site_label\"]\n",
    "    for element in unique_elements:\n",
    "        selected_index = atom_df[atom_df[\"_atom_site_type_symbol\"]==element].index\n",
    "        natoms_per_element[element] = len(selected_index)\n",
    "        atom_idx_offset[selected_index] = natoms_per_element[element]\n",
    "\n",
    "        atom_df.loc[selected_index, \"_atom_site_label_postfix\"] = [x for x in range(1, len(selected_index)+1)]\n",
    "        atom_df.loc[selected_index, \"_atom_site_label\"] = element + atom_df.loc[selected_index, \"_atom_site_label_postfix\"].astype(str)\n",
    "    # label_map_dict = dict(zip(atom_df[\"_atom_site_label_save\"].to_list() + atom_df[\"_atom_site_label\"].to_list(),\n",
    "    #                           atom_df[\"_atom_site_label\"].to_list() + atom_df[\"_atom_site_label\"].to_list()))\n",
    "    label_map_dict = dict(zip(atom_df[\"_atom_site_label_save\"].to_list(),\n",
    "                          atom_df[\"_atom_site_label\"].to_list()))\n",
    "    for old_label_idx in range(0, len(atom_df[\"_atom_site_label\"])):\n",
    "        if atom_df.at[old_label_idx, \"_atom_site_label\"] not in label_map_dict:\n",
    "            label_map_dict[atom_df.at[old_label_idx, \"_atom_site_label\"]] = atom_df.at[old_label_idx, \"_atom_site_label\"]\n",
    "    if type(bond_df) != type(None):\n",
    "        bond_df[\"_geom_bond_atom_site_label_1_save\"] = bond_df[\"_geom_bond_atom_site_label_1\"]\n",
    "        bond_df[\"_geom_bond_atom_site_label_1\"] = bond_df[\"_geom_bond_atom_site_label_1\"].map(label_map_dict)\n",
    "        bond_df[\"_geom_bond_atom_site_label_2_save\"] = bond_df[\"_geom_bond_atom_site_label_2\"]\n",
    "        bond_df[\"_geom_bond_atom_site_label_2\"] = bond_df[\"_geom_bond_atom_site_label_2\"].map(label_map_dict)\n",
    "        bond_df[\"_geom_bond_atom_site_label_1_prefix\"] = bond_df[\"_geom_bond_atom_site_label_1\"].apply(lambda x: re.findall(r\"[A-Z]*[a-z]*\", x)[0])\n",
    "        bond_df[\"_geom_bond_atom_site_label_1_postfix\"] = bond_df[\"_geom_bond_atom_site_label_1\"].apply(lambda x: re.findall(r\"[0-9]+\", x)[0])\n",
    "        bond_df[\"_geom_bond_atom_site_label_2_prefix\"] = bond_df[\"_geom_bond_atom_site_label_2\"].apply(lambda x: re.findall(r\"[A-Z]*[a-z]*\", x)[0])\n",
    "        bond_df[\"_geom_bond_atom_site_label_2_postfix\"] = bond_df[\"_geom_bond_atom_site_label_2\"].apply(lambda x: re.findall(r\"[0-9]+\", x)[0])\n",
    "        bond_df_atom_idx_offset1 = np.zeros(len(bond_df), dtype=int)\n",
    "        bond_df_atom_idx_offset2 = np.zeros(len(bond_df), dtype=int)\n",
    "        for element in unique_elements:\n",
    "            bond_df_selected_index = bond_df[bond_df[\"_geom_bond_atom_site_label_1_prefix\"]==element].index\n",
    "            bond_df_atom_idx_offset1[bond_df_selected_index] = natoms_per_element[element]\n",
    "            bond_df_selected_index = bond_df[bond_df[\"_geom_bond_atom_site_label_2_prefix\"]==element].index\n",
    "            bond_df_atom_idx_offset2[bond_df_selected_index] = natoms_per_element[element]\n",
    "        bond_df_list = [bond_df.copy(deep=True)]\n",
    "\n",
    "    atom_df[\"original_label\"] = atom_df[\"_atom_site_label\"].to_list()\n",
    "    atom_df[\"periodic_image\"] = \"[0, 0, 0]\"\n",
    "    atom_df_list = [atom_df.copy(deep=True)]\n",
    "\n",
    "    displacement_vectors = [[0,0,1], [0,0,-1],\n",
    "                            [0,1,0], [0,-1,0],\n",
    "                            [1,0,0], [-1,0,0],\n",
    "                            [-1,-1,0], [-1,1,0], [1,-1,0], [1,1,0],\n",
    "                            [-1,0,-1], [-1,0,1], [1,0,-1], [1,0,1],\n",
    "                            [0,-1,-1], [0,-1,1], [0,1,-1], [0,1,1],\n",
    "                            [-1,-1,-1], [-1,-1,1], [-1,1,-1], [1,-1,-1],\n",
    "                            [-1,1,1], [1,-1,1], [1,1,-1], [1,1,1]]\n",
    "\n",
    "    for disp_i in range(0, len(displacement_vectors)):\n",
    "        disp = displacement_vectors[disp_i]\n",
    "        if type(bond_df) != type(None):\n",
    "            _bond_df = bond_df.copy(deep=True)\n",
    "            _bond_df[\"_geom_bond_atom_site_label_1_postfix\"] = ((disp_i + 1) * bond_df_atom_idx_offset1 + \\\n",
    "                                                                _bond_df[\"_geom_bond_atom_site_label_1_postfix\"].astype(int)).astype(str)\n",
    "            _bond_df[\"_geom_bond_atom_site_label_1\"] = _bond_df[\"_geom_bond_atom_site_label_1_prefix\"] + _bond_df[\"_geom_bond_atom_site_label_1_postfix\"]\n",
    "            _bond_df[\"_geom_bond_atom_site_label_2_postfix\"] = ((disp_i + 1) * bond_df_atom_idx_offset2 + \\\n",
    "                                                                _bond_df[\"_geom_bond_atom_site_label_2_postfix\"].astype(int)).astype(str)\n",
    "            _bond_df[\"_geom_bond_atom_site_label_2\"] = _bond_df[\"_geom_bond_atom_site_label_2_prefix\"] + _bond_df[\"_geom_bond_atom_site_label_2_postfix\"]\n",
    "            bond_df_list.append(_bond_df)\n",
    "\n",
    "        _atom_df = atom_df.copy(deep=True)\n",
    "        _atom_df.loc[:, \"periodic_image\"] = str(disp)\n",
    "        _atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                         \"_atom_site_fract_y\",\n",
    "                         \"_atom_site_fract_z\"]] = _atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                                   \"_atom_site_fract_y\",\n",
    "                                                                   \"_atom_site_fract_z\"]].values + np.array(disp)\n",
    "        _atom_df[\"_atom_site_label_postfix\"] = ((disp_i + 1) * atom_idx_offset + _atom_df[\"_atom_site_label_postfix\"].astype(int)).astype(str)\n",
    "        _atom_df[\"original_label\"] = _atom_df[\"_atom_site_label\"].to_list()\n",
    "        _atom_df[\"_atom_site_label\"] = _atom_df[\"_atom_site_type_symbol\"] + _atom_df[\"_atom_site_label_postfix\"]\n",
    "\n",
    "        atom_df_list.append(_atom_df)\n",
    "\n",
    "    atom_df = pd.concat(atom_df_list, axis=0).reset_index(drop=True)\n",
    "    if type(bond_df) != type(None):\n",
    "        bond_df = pd.concat(bond_df_list, axis=0).reset_index(drop=True)\n",
    "\n",
    "    atom_df.loc[:, [\"x\", \"y\", \"z\"]] = atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                      \"_atom_site_fract_y\",\n",
    "                                                      \"_atom_site_fract_z\"]].values @ M\n",
    "    unit_cell_expansion_offset = 2 # Angstrom\n",
    "    critical_points = [np.array([-1, -1, -1])*unit_cell_expansion_offset,\n",
    "                       np.array([1, -1, -1])*unit_cell_expansion_offset + A,\n",
    "                       np.array([-1, 1, -1])*unit_cell_expansion_offset + B,\n",
    "                       np.array([-1, -1, 1])*unit_cell_expansion_offset + C,\n",
    "                       np.array([1, 1, -1])*unit_cell_expansion_offset + A + B,\n",
    "                       np.array([-1, 1, 1])*unit_cell_expansion_offset + B + C,\n",
    "                       np.array([1, -1, 1])*unit_cell_expansion_offset + A + C,\n",
    "                       np.array([1, 1, 1])*unit_cell_expansion_offset + A + B + C]\n",
    "    hull = Delaunay(critical_points)\n",
    "    #tol=0.01\n",
    "\n",
    "    isInHull = hull.find_simplex(atom_df.loc[:, [\"x\", \"y\", \"z\"]].values)>=-tol\n",
    "    atom_df = atom_df[isInHull].copy(deep=True)\n",
    "    atom_df.loc[:, [\"x\", \"y\", \"z\"]] = atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                      \"_atom_site_fract_y\",\n",
    "                                                      \"_atom_site_fract_z\"]].values @ M\n",
    "\n",
    "    bond_scatter = []\n",
    "\n",
    "    if type(bond_df) != type(None):\n",
    "        bond_df[\"atom1\"] = None\n",
    "        bond_df[\"atom2\"] = None\n",
    "        bond_df[\"atom1\"] = bond_df[\"_geom_bond_atom_site_label_1\"].map(dict(zip(atom_df[\"_atom_site_label\"], atom_df.index)))\n",
    "        bond_df[\"atom2\"] = bond_df[\"_geom_bond_atom_site_label_2\"].map(dict(zip(atom_df[\"_atom_site_label\"], atom_df.index)))\n",
    "        bond_df = bond_df.dropna()\n",
    "        bond_df[\"atom1\"] = bond_df[\"atom1\"].astype(int)\n",
    "        bond_df[\"atom2\"] = bond_df[\"atom2\"].astype(int)\n",
    "        bond_df[\"dist_sqr\"] = [np.sum((atom_df.loc[bond_df.at[i, \"atom1\"].astype(int), [\"x\", \"y\", \"z\"]].values - \\\n",
    "                                       atom_df.loc[bond_df.at[i, \"atom2\"].astype(int), [\"x\", \"y\", \"z\"]].values) ** 2) for i in bond_df.index]\n",
    "\n",
    "        for i in bond_df.index:\n",
    "            orig_label1 = atom_df.at[bond_df.at[i, \"atom1\"], \"original_label\"]\n",
    "            affiliated_atoms1 = atom_df[atom_df[\"original_label\"]==orig_label1].copy(deep=True).reset_index(drop=True)\n",
    "            orig_label2 = atom_df.at[bond_df.at[i, \"atom2\"], \"original_label\"]\n",
    "            affiliated_atoms2 = atom_df[atom_df[\"original_label\"]==orig_label2].copy(deep=True).reset_index(drop=True)\n",
    "            possible_bonds = pd.concat([pd.DataFrame(np.repeat(affiliated_atoms1.values, len(affiliated_atoms2), axis=0), columns=affiliated_atoms1.columns + \"_1\"),\n",
    "                                        pd.DataFrame(np.tile(affiliated_atoms2.values, (len(affiliated_atoms1), 1)), columns=affiliated_atoms2.columns + \"_2\")], axis=1)\n",
    "            possible_bonds[\"dist_sqr\"] = np.sum((possible_bonds.loc[:, [\"x_1\", \"y_1\", \"z_1\"]].values - possible_bonds.loc[:, [\"x_2\", \"y_2\", \"z_2\"]].values) ** 2, axis=1)\n",
    "            possible_bonds = possible_bonds[possible_bonds[\"dist_sqr\"]<bond_dist_sqr_threshold]\n",
    "            for bond_idx in possible_bonds.index:\n",
    "                bond_scatter.append(\n",
    "                    go.Scatter3d(\n",
    "                        x=[possible_bonds.at[bond_idx, \"x_1\"], possible_bonds.at[bond_idx, \"x_2\"]],\n",
    "                        y=[possible_bonds.at[bond_idx, \"y_1\"], possible_bonds.at[bond_idx, \"y_2\"]],\n",
    "                        z=[possible_bonds.at[bond_idx, \"z_1\"], possible_bonds.at[bond_idx, \"z_2\"]],\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(\n",
    "                            color='rgba(100, 100, 255, 0.5)',\n",
    "                            width=5,\n",
    "                        ),\n",
    "                        showlegend=False,\n",
    "                        hoverinfo='skip')\n",
    "                )\n",
    "\n",
    "    unit_cell = [[np.array([0, 0, 0]), A], [np.array([0, 0, 0]), B], [np.array([0, 0, 0]), C],\n",
    "                 [A, A+B], [A, A+C], [B, B+A],\n",
    "                 [B, B+C], [C, C+A], [C, C+B],\n",
    "                 [A+B, A+B+C], [B+C, A+B+C], [A+C, A+B+C]]\n",
    "    unit_cell_color = [\"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\",\n",
    "                       \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\",\n",
    "                       \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\",\n",
    "                       \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\", \"rgba(255, 255, 0, 1)\"]\n",
    "\n",
    "    # XYZ arrows\n",
    "    axis_length = 0.5\n",
    "    V_diag = 0.25 * (A + B + C)\n",
    "    x_start = -V_diag[0]\n",
    "    y_start = -V_diag[1]\n",
    "    z_start = -V_diag[2]\n",
    "    x_end1 = (axis_length * A - V_diag)[0]\n",
    "    y_end1 = (axis_length * A - V_diag)[1]\n",
    "    z_end1 = (axis_length * A - V_diag)[2]\n",
    "    x_end2 = (axis_length * B - V_diag)[0]\n",
    "    y_end2 = (axis_length * B - V_diag)[1]\n",
    "    z_end2 = (axis_length * B - V_diag)[2]\n",
    "    x_end3 = (axis_length * C - V_diag)[0]\n",
    "    y_end3 = (axis_length * C - V_diag)[1]\n",
    "    z_end3 = (axis_length * C - V_diag)[2]\n",
    "    arrows = [\n",
    "        go.Scatter3d(x=[x_start, x_end1],\n",
    "                     y=[y_start, y_end1],\n",
    "                     z=[z_start, z_end1],\n",
    "                     mode=\"lines+text\",\n",
    "                     text=[\"\", \"A\"],\n",
    "                     line=dict(\n",
    "                         color='rgba(255, 0, 0, 1)',\n",
    "                         width=5,\n",
    "                     ),\n",
    "                     textfont=dict(\n",
    "                         color='rgba(255, 0, 0, 1)',\n",
    "                         size=20,\n",
    "                     ),\n",
    "                     showlegend=False,\n",
    "                     hoverinfo='skip',\n",
    "        ),\n",
    "        go.Scatter3d(x=[x_start, x_end2],\n",
    "                     y=[y_start, y_end2],\n",
    "                     z=[z_start, z_end2],\n",
    "                     mode=\"lines+text\",\n",
    "                     text=[\"\", \"B\"],\n",
    "                     line=dict(\n",
    "                         color='rgba(0, 255, 0, 1)',\n",
    "                         width=5,\n",
    "                     ),\n",
    "                     textfont=dict(\n",
    "                         color='rgba(0, 255, 0, 1)',\n",
    "                         size=20,\n",
    "                     ),\n",
    "                     showlegend=False,\n",
    "                     hoverinfo='skip',\n",
    "        ),\n",
    "        go.Scatter3d(x=[x_start, x_end3],\n",
    "                     y=[y_start, y_end3],\n",
    "                     z=[z_start, z_end3],\n",
    "                     mode=\"lines+text\",\n",
    "                     text=[\"\", \"C\"],\n",
    "                     line=dict(\n",
    "                         color='rgba(0, 0, 255, 1)',\n",
    "                         width=5,\n",
    "                     ),\n",
    "                     textfont=dict(\n",
    "                         color='rgba(0, 0, 255, 1)',\n",
    "                         size=20,\n",
    "                     ),\n",
    "                     showlegend=False,\n",
    "                     hoverinfo='skip',\n",
    "        ),\n",
    "    ]\n",
    "    atom_df[\"color\"] = \"#\" + atom_df[\"_atom_site_type_symbol\"].map(symbol2color)\n",
    "    data=[go.Scatter3d(x=atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"x\"],\n",
    "                       y=atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"y\"],\n",
    "                       z=atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"z\"],\n",
    "                       text=atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"_atom_site_type_symbol\"] + \"<br>\" + \\\n",
    "                            atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"_atom_site_label\"] + \"<br>\" + \\\n",
    "                            atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"periodic_image\"] + \"<br>was \" + \\\n",
    "                            atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"original_label\"],\n",
    "                       mode='markers',\n",
    "                       showlegend=True,\n",
    "                       name=k,\n",
    "                       marker=dict(\n",
    "                           color=atom_df[atom_df[\"_atom_site_type_symbol\"]==k].loc[:, \"color\"],\n",
    "                           size=10,\n",
    "                           opacity=1.0,\n",
    "                       )) for k in unique_elements] + \\\n",
    "                       bond_scatter + [go.Scatter3d(x=np.array(unit_cell[i]).T[0],\n",
    "                                                    y=np.array(unit_cell[i]).T[1],\n",
    "                                                    z=np.array(unit_cell[i]).T[2],\n",
    "                                                    mode=\"lines\",\n",
    "                                                    line=dict(\n",
    "                                                        color=unit_cell_color[i],\n",
    "                                                        width=2,\n",
    "                                                    ),\n",
    "                                                    showlegend=False,\n",
    "                                                    hoverinfo='skip') for i in range(0, len(unit_cell))] + arrows\n",
    "\n",
    "    xyzmin = min([atom_df[\"x\"].min(), atom_df[\"y\"].min(), atom_df[\"z\"].min(), np.array(unit_cell).min(), (0-V_diag).min()])\n",
    "    xyzmax = max([atom_df[\"x\"].max(), atom_df[\"y\"].max(), atom_df[\"z\"].max(), np.array(unit_cell).max(), (0-V_diag).max()])\n",
    "    DeltaX = xyzmax - xyzmin\n",
    "    padding_xyz = DeltaX * 0.05\n",
    "    fig = go.Figure(data=data)\n",
    "    annotation_list = []\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            annotations=annotation_list,\n",
    "            xaxis = dict(nticks=10, range=[xyzmin-padding_xyz,xyzmax+padding_xyz],\n",
    "                         backgroundcolor=\"rgba(80, 70, 70, 0.5)\",\n",
    "                         gridcolor=\"white\",\n",
    "                         showbackground=showbackground,\n",
    "                         showgrid=False,\n",
    "                         zeroline=False,\n",
    "                         showticklabels=False,\n",
    "                         visible=False,\n",
    "                         #zerolinecolor=\"white\",\n",
    "                        ),\n",
    "            yaxis = dict(nticks=10, range=[xyzmin-padding_xyz, xyzmax+padding_xyz],\n",
    "                         backgroundcolor=\"rgba(70, 80, 70, 0.5)\",\n",
    "                         gridcolor=\"white\",\n",
    "                         showbackground=showbackground,\n",
    "                         showgrid=False,\n",
    "                         zeroline=False,\n",
    "                         showticklabels=False,\n",
    "                         visible=False,\n",
    "                         #zerolinecolor=\"white\",\n",
    "                        ),\n",
    "            zaxis = dict(nticks=10, range=[xyzmin-padding_xyz, xyzmax+padding_xyz],\n",
    "                         backgroundcolor=\"rgba(70, 70, 80, 0.5)\",\n",
    "                         gridcolor=\"white\",\n",
    "                         showbackground=showbackground,\n",
    "                         showgrid=False,\n",
    "                         zeroline=False,\n",
    "                         showticklabels=False,\n",
    "                         visible=False,\n",
    "                         #zerolinecolor=\"white\",\n",
    "                        ),\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        margin=dict(r=10, l=10, b=10, t=10),\n",
    "        showlegend=True)\n",
    "    fig.update_layout(scene_aspectmode='cube',\n",
    "                      paper_bgcolor='rgba(0,0,0,0)',\n",
    "                      plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(\n",
    "        font_color=\"rgba(150,150,150,1)\",\n",
    "        title_font_color=\"rgba(150,150,150,1)\",\n",
    "        legend_title_font_color=\"rgba(150,150,150,1)\",\n",
    "    )\n",
    "\n",
    "    if _cif_name != cif_name:\n",
    "        os.remove(cif_name)\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(\"PeriodicTableJSON.json\", \"rb\") as f:\n",
    "    table_dict = json.load(f)\n",
    "element_df = pd.DataFrame(table_dict[\"elements\"])\n",
    "element_df[\"cpk-hex\"] = element_df[\"cpk-hex\"].fillna(\"0000ff\")\n",
    "symbol2color = dict(zip(element_df[\"symbol\"], element_df[\"cpk-hex\"]))\n",
    "symbol2color[\"X\"] = \"0000ff\"\n",
    "idx2symbol = dict(zip(element_df[\"number\"], element_df[\"symbol\"]))\n",
    "idx2symbol[0] = \"X\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cif_name=f\"{inDir}/cifs/{fName}\"\n",
    "atom_df = read_cif_xyz(cif_name+\".cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fract_disp=np.array([0, 0, 0])\n",
    "\n",
    "showbackground=False\n",
    "tol=0.01\n",
    "bond_dist_sqr_threshold=6\n",
    "\n",
    "def grabAtomDF(cif_name, fract_disp=np.array([0, 0, 0]), showbackground=False, tol=0.01, bond_dist_sqr_threshold=6):\n",
    "\n",
    "\n",
    "\n",
    "    with io.open(\"PeriodicTableJSON.json\", \"rb\") as f:\n",
    "        table_dict = json.load(f)\n",
    "    element_df = pd.DataFrame(table_dict[\"elements\"])\n",
    "    element_df[\"cpk-hex\"] = element_df[\"cpk-hex\"].fillna(\"0000ff\")\n",
    "    symbol2color = dict(zip(element_df[\"symbol\"], element_df[\"cpk-hex\"]))\n",
    "    symbol2color[\"X\"] = \"0000ff\"\n",
    "    idx2symbol = dict(zip(element_df[\"number\"], element_df[\"symbol\"]))\n",
    "    idx2symbol[0] = \"X\"\n",
    "\n",
    "    _cif_name = cif_name\n",
    "    #cif_str = None\n",
    "    with io.open(cif_name, \"r\", newline=\"\\n\") as cif:\n",
    "        cif_str = cif.read().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    cif_list = cif_str.split(\"loop_\")\n",
    "    for cif_section in cif_list:\n",
    "        if \"_symmetry_equiv_pos_as_xyz\" in cif_section:\n",
    "            if len(cif_section.split(\"_cell_\")[0].split(\"_symmetry_equiv_pos_as_xyz\")[1].strip().split(\"\\n\")) > 1:\n",
    "                cif_name = cif_name.replace(\".cif\", \"_P1.cif\")\n",
    "                CifWriter(mg.Structure.from_str(cif_str, fmt=\"cif\"), refine_struct=False).write_file(cif_name)\n",
    "\n",
    "\n",
    "    M = lat_param2vec(read_cif_lattice_param(cif_name))\n",
    "    A, B, C = M\n",
    "    atom_df = read_cif_xyz(cif_name)\n",
    "    bond_df = read_cif_bond(cif_name)\n",
    "\n",
    "    #bond_df = None\n",
    "    Natoms = len(atom_df)\n",
    "    atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                    \"_atom_site_fract_y\",\n",
    "                    \"_atom_site_fract_z\"]] = (atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                              \"_atom_site_fract_y\",\n",
    "                                                              \"_atom_site_fract_z\"]].values + fract_disp) % 1# - np.array([0.5, 0.5, 0.5])) % 1\n",
    "    atom_df[\"x\"] = None\n",
    "    atom_df[\"y\"] = None\n",
    "    atom_df[\"z\"] = None\n",
    "    atom_df[\"_atom_site_label_prefix\"] = atom_df[\"_atom_site_label\"].apply(lambda x: re.findall(r\"[A-Z]*[a-z]*\", x)[0])\n",
    "    atom_df[\"_atom_site_label_postfix\"] = atom_df[\"_atom_site_label\"].apply(lambda x: re.findall(r\"[0-9]+\", x)[0])\n",
    "\n",
    "\n",
    "    error_atom_index = atom_df[atom_df[\"_atom_site_label_prefix\"]!=atom_df[\"_atom_site_type_symbol\"]].index\n",
    "    atom_df.loc[error_atom_index, \"_atom_site_label\"] = atom_df.loc[error_atom_index, \"_atom_site_type_symbol\"].astype(str) + \\\n",
    "                                                        atom_df.loc[error_atom_index, \"_atom_site_label_postfix\"].astype(str)\n",
    "\n",
    "    unique_elements = sorted(atom_df[\"_atom_site_type_symbol\"].unique().tolist())\n",
    "    natoms_per_element = {}\n",
    "    atom_idx_offset = np.zeros(Natoms, dtype=int)\n",
    "    atom_df.loc[:, \"_atom_site_label_save\"] = atom_df.loc[:, \"_atom_site_label\"]\n",
    "    for element in unique_elements:\n",
    "        selected_index = atom_df[atom_df[\"_atom_site_type_symbol\"]==element].index\n",
    "        natoms_per_element[element] = len(selected_index)\n",
    "        atom_idx_offset[selected_index] = natoms_per_element[element]\n",
    "\n",
    "        atom_df.loc[selected_index, \"_atom_site_label_postfix\"] = [x for x in range(1, len(selected_index)+1)]\n",
    "        atom_df.loc[selected_index, \"_atom_site_label\"] = element + atom_df.loc[selected_index, \"_atom_site_label_postfix\"].astype(str)\n",
    "    # label_map_dict = dict(zip(atom_df[\"_atom_site_label_save\"].to_list() + atom_df[\"_atom_site_label\"].to_list(),\n",
    "    #                           atom_df[\"_atom_site_label\"].to_list() + atom_df[\"_atom_site_label\"].to_list()))\n",
    "    label_map_dict = dict(zip(atom_df[\"_atom_site_label_save\"].to_list(),\n",
    "                          atom_df[\"_atom_site_label\"].to_list()))\n",
    "    for old_label_idx in range(0, len(atom_df[\"_atom_site_label\"])):\n",
    "        if atom_df.at[old_label_idx, \"_atom_site_label\"] not in label_map_dict:\n",
    "            label_map_dict[atom_df.at[old_label_idx, \"_atom_site_label\"]] = atom_df.at[old_label_idx, \"_atom_site_label\"]\n",
    "    if type(bond_df) != type(None):\n",
    "        bond_df[\"_geom_bond_atom_site_label_1_save\"] = bond_df[\"_geom_bond_atom_site_label_1\"]\n",
    "        bond_df[\"_geom_bond_atom_site_label_1\"] = bond_df[\"_geom_bond_atom_site_label_1\"].map(label_map_dict)\n",
    "        bond_df[\"_geom_bond_atom_site_label_2_save\"] = bond_df[\"_geom_bond_atom_site_label_2\"]\n",
    "        bond_df[\"_geom_bond_atom_site_label_2\"] = bond_df[\"_geom_bond_atom_site_label_2\"].map(label_map_dict)\n",
    "        bond_df[\"_geom_bond_atom_site_label_1_prefix\"] = bond_df[\"_geom_bond_atom_site_label_1\"].apply(lambda x: re.findall(r\"[A-Z]*[a-z]*\", x)[0])\n",
    "        bond_df[\"_geom_bond_atom_site_label_1_postfix\"] = bond_df[\"_geom_bond_atom_site_label_1\"].apply(lambda x: re.findall(r\"[0-9]+\", x)[0])\n",
    "        bond_df[\"_geom_bond_atom_site_label_2_prefix\"] = bond_df[\"_geom_bond_atom_site_label_2\"].apply(lambda x: re.findall(r\"[A-Z]*[a-z]*\", x)[0])\n",
    "        bond_df[\"_geom_bond_atom_site_label_2_postfix\"] = bond_df[\"_geom_bond_atom_site_label_2\"].apply(lambda x: re.findall(r\"[0-9]+\", x)[0])\n",
    "        bond_df_atom_idx_offset1 = np.zeros(len(bond_df), dtype=int)\n",
    "        bond_df_atom_idx_offset2 = np.zeros(len(bond_df), dtype=int)\n",
    "        for element in unique_elements:\n",
    "            bond_df_selected_index = bond_df[bond_df[\"_geom_bond_atom_site_label_1_prefix\"]==element].index\n",
    "            bond_df_atom_idx_offset1[bond_df_selected_index] = natoms_per_element[element]\n",
    "            bond_df_selected_index = bond_df[bond_df[\"_geom_bond_atom_site_label_2_prefix\"]==element].index\n",
    "            bond_df_atom_idx_offset2[bond_df_selected_index] = natoms_per_element[element]\n",
    "        bond_df_list = [bond_df.copy(deep=True)]\n",
    "\n",
    "    atom_df[\"original_label\"] = atom_df[\"_atom_site_label\"].to_list()\n",
    "    atom_df[\"periodic_image\"] = \"[0, 0, 0]\"\n",
    "    atom_df_list = [atom_df.copy(deep=True)]\n",
    "\n",
    "    displacement_vectors = [[0,0,1], [0,0,-1],\n",
    "                            [0,1,0], [0,-1,0],\n",
    "                            [1,0,0], [-1,0,0],\n",
    "                            [-1,-1,0], [-1,1,0], [1,-1,0], [1,1,0],\n",
    "                            [-1,0,-1], [-1,0,1], [1,0,-1], [1,0,1],\n",
    "                            [0,-1,-1], [0,-1,1], [0,1,-1], [0,1,1],\n",
    "                            [-1,-1,-1], [-1,-1,1], [-1,1,-1], [1,-1,-1],\n",
    "                            [-1,1,1], [1,-1,1], [1,1,-1], [1,1,1]]\n",
    "\n",
    "    for disp_i in range(0, len(displacement_vectors)):\n",
    "        disp = displacement_vectors[disp_i]\n",
    "        if type(bond_df) != type(None):\n",
    "            _bond_df = bond_df.copy(deep=True)\n",
    "            _bond_df[\"_geom_bond_atom_site_label_1_postfix\"] = ((disp_i + 1) * bond_df_atom_idx_offset1 + \\\n",
    "                                                                _bond_df[\"_geom_bond_atom_site_label_1_postfix\"].astype(int)).astype(str)\n",
    "            _bond_df[\"_geom_bond_atom_site_label_1\"] = _bond_df[\"_geom_bond_atom_site_label_1_prefix\"] + _bond_df[\"_geom_bond_atom_site_label_1_postfix\"]\n",
    "            _bond_df[\"_geom_bond_atom_site_label_2_postfix\"] = ((disp_i + 1) * bond_df_atom_idx_offset2 + \\\n",
    "                                                                _bond_df[\"_geom_bond_atom_site_label_2_postfix\"].astype(int)).astype(str)\n",
    "            _bond_df[\"_geom_bond_atom_site_label_2\"] = _bond_df[\"_geom_bond_atom_site_label_2_prefix\"] + _bond_df[\"_geom_bond_atom_site_label_2_postfix\"]\n",
    "            bond_df_list.append(_bond_df)\n",
    "\n",
    "        _atom_df = atom_df.copy(deep=True)\n",
    "        _atom_df.loc[:, \"periodic_image\"] = str(disp)\n",
    "        _atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                         \"_atom_site_fract_y\",\n",
    "                         \"_atom_site_fract_z\"]] = _atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                                   \"_atom_site_fract_y\",\n",
    "                                                                   \"_atom_site_fract_z\"]].values + np.array(disp)\n",
    "        _atom_df[\"_atom_site_label_postfix\"] = ((disp_i + 1) * atom_idx_offset + _atom_df[\"_atom_site_label_postfix\"].astype(int)).astype(str)\n",
    "        _atom_df[\"original_label\"] = _atom_df[\"_atom_site_label\"].to_list()\n",
    "        _atom_df[\"_atom_site_label\"] = _atom_df[\"_atom_site_type_symbol\"] + _atom_df[\"_atom_site_label_postfix\"]\n",
    "\n",
    "        atom_df_list.append(_atom_df)\n",
    "\n",
    "    atom_df = pd.concat(atom_df_list, axis=0).reset_index(drop=True)\n",
    "    if type(bond_df) != type(None):\n",
    "        bond_df = pd.concat(bond_df_list, axis=0).reset_index(drop=True)\n",
    "\n",
    "    atom_df.loc[:, [\"x\", \"y\", \"z\"]] = atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                      \"_atom_site_fract_y\",\n",
    "                                                      \"_atom_site_fract_z\"]].values @ M\n",
    "    unit_cell_expansion_offset = 2 # Angstrom\n",
    "    critical_points = [np.array([-1, -1, -1])*unit_cell_expansion_offset,\n",
    "                       np.array([1, -1, -1])*unit_cell_expansion_offset + A,\n",
    "                       np.array([-1, 1, -1])*unit_cell_expansion_offset + B,\n",
    "                       np.array([-1, -1, 1])*unit_cell_expansion_offset + C,\n",
    "                       np.array([1, 1, -1])*unit_cell_expansion_offset + A + B,\n",
    "                       np.array([-1, 1, 1])*unit_cell_expansion_offset + B + C,\n",
    "                       np.array([1, -1, 1])*unit_cell_expansion_offset + A + C,\n",
    "                       np.array([1, 1, 1])*unit_cell_expansion_offset + A + B + C]\n",
    "    hull = Delaunay(critical_points)\n",
    "    #tol=0.01\n",
    "\n",
    "    isInHull = hull.find_simplex(atom_df.loc[:, [\"x\", \"y\", \"z\"]].values)>=-tol\n",
    "    atom_df = atom_df[isInHull].copy(deep=True)\n",
    "    atom_df.loc[:, [\"x\", \"y\", \"z\"]] = atom_df.loc[:, [\"_atom_site_fract_x\",\n",
    "                                                      \"_atom_site_fract_y\",\n",
    "                                                      \"_atom_site_fract_z\"]].values @ M\n",
    "    return atom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_df.loc[:, [\"x\", \"y\", \"z\"]].to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(f\"{inDir}/post-combustion-vsa-2-clean.csv\",index_col=0)\n",
    "\n",
    "\n",
    "# grab 4 bins for each, trP% of samples within regions\n",
    "##\n",
    "## workingCap: [0-1,1-2,2-4,4-]\n",
    "## selectivity: [0-50,50-200,200-400,400-]\n",
    "trP=.70\n",
    "totalLen=len(df['selectivity'])\n",
    "regVars=['selectivity','mmol/g_working_capacity']\n",
    "bounds={\"selectivity\":[(0,50),(50,200),(200,400),(400,)],\"mmol/g_working_capacity\":[(0,1),(1,2),(2,4),(4,)]}\n",
    "\n",
    "indexBounds={k:[] for k in bounds.keys()} #upper index for\n",
    "\n",
    "for k in regVars:\n",
    "    j=0\n",
    "    bj=0\n",
    "    for index,row in df.sort_values(by=[k]).iterrows():\n",
    "        if bj>=len(bounds[k])-1:\n",
    "            break\n",
    "        elif row[k]>bounds[k][bj][1]:\n",
    "            indexBounds[k].append(j)\n",
    "            bj+=1\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexBounds['selectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexBounds['sel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed, then random indices up to\n",
    "\n",
    "np.random.seed(42)\n",
    "testBins={k:[] for k in bounds.keys()}\n",
    "for k in bounds.keys():\n",
    "    j=0\n",
    "    testBins[k].append(list(np.random.choice(df.sort_values(by=[k]).index[:indexBounds[k][j]],size=round((1-trP)*indexBounds[k][j]),replace=False)))\n",
    "    for j in range(1,len(indexBounds[k])):\n",
    "        testBins[k].append(list(np.random.choice(df.sort_values(by=[k]).index[indexBounds[k][j-1]:indexBounds[k][j]],size=round((1-trP)*(indexBounds[k][j]-indexBounds[k][j-1])),replace=False)))\n",
    "    testBins[k].append(list(np.random.choice(df.sort_values(by=[k]).index[indexBounds[k][-1]:],size=round((1-trP)*(totalLen-indexBounds[k][-1])),replace=False)))\n",
    "\n",
    "\n",
    "\n",
    "trainBins={k:[] for k in bounds.keys()}\n",
    "for k in bounds.keys():\n",
    "    j=0\n",
    "    trainBins[k].append(list(set(df.sort_values(by=[k]).index[:indexBounds[k][j]])-set(testBins[k][j])))\n",
    "    for j in range(1,len(indexBounds[k])):\n",
    "        trainBins[k].append(list(set(df.sort_values(by=[k]).index[indexBounds[k][j-1]:indexBounds[k][j]])-set(testBins[k][j])))\n",
    "    trainBins[k].append(list(set(df.sort_values(by=[k]).index[indexBounds[k][-1]:])-set(testBins[k][-1])))\n",
    "\n",
    "\n",
    "#  testBins[\"selectivity\"] -> list of sampled bins along selectivity bounds\n",
    "#testBins['selectivity'][0] selects lowest selective MOFS sample <-> 4 bins, {k:{\"low\":[MOFIDs for low selectivity],\"med\"...,\"high\",\"superHigh\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best and worst performers available in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapCO2 & set(testBins[\"mmol/g_working_capacity\"][3]) & set(testBins[\"selectivity\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBins[\"selectivity\"][3] # good mof sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapCO2 & set(testBins[\"mmol/g_working_capacity\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapCO2 & set(testBins[\"selectivity\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestMOF=\"DB12-NEYZAU_clean\"\n",
    "worstMOF=\"DB12-CAKXUJ_clean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## worst mofs we have available below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapCO2 & set(testBins[\"mmol/g_working_capacity\"][0]) & set(testBins[\"selectivity\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapCO2 & set(testBins[\"selectivity\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[j for j in testBins[\"mmol/g_working_capacity\"][3] if j not in testBins[\"selectivity\"][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(testBins.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIF2XYZ CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredAtoms=set(os.listdir(f\"{inDir}/cifPointClouds\"))-{\"total\"}\n",
    "for fName in [bestMOF,worstMOF]:\n",
    "    fName+=\".cif\"\n",
    "    cif_name=f\"{inDir}/cifs/{fName}\"\n",
    "    atom_df = grabAtomDF(cif_name)\n",
    "\n",
    "    atom_df.loc[:, [\"x\", \"y\", \"z\"]].to_csv(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\",index=False)\n",
    "\n",
    "    for a in set(atom_df['_atom_site_label_prefix']):\n",
    "        if a not in exploredAtoms:\n",
    "            exploredAtoms.add(a)\n",
    "            try:\n",
    "                os.mkdir(f\"{inDir}/cifPointClouds/{a}\")\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            subXYZ=atom_df[atom_df['_atom_site_label_prefix'] == a]\n",
    "            subXYZ.loc[:, [\"x\", \"y\", \"z\"]].to_csv(f\"{inDir}/cifPointClouds/{a}/{fName[:-3]}csv\",index=False)\n",
    "        except:\n",
    "            print(f\"error with atom lab {a} in {fName} !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testBins[\"selectivity\"][3]  # good mof sample\n",
    "\n",
    "for fName in [bestMOF,worstMOF]:#testBins[\"mmol/g_working_capacity\"][3]:\n",
    "    fName += \".cif\"\n",
    "    cif_name = f\"{inDir}/cifs/{fName}\"\n",
    "    atom_df = grabAtomDF(cif_name)\n",
    "\n",
    "    atom_df.loc[:, [\"x\", \"y\", \"z\"]].to_csv(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", index=False)\n",
    "\n",
    "    for a in set(atom_df['_atom_site_label_prefix']):\n",
    "        if a not in exploredAtoms:\n",
    "            exploredAtoms.add(a)\n",
    "            try:\n",
    "                os.mkdir(f\"{inDir}/cifPointClouds/{a}\")\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            subXYZ = atom_df[atom_df['_atom_site_label_prefix'] == a]\n",
    "            subXYZ.loc[:, [\"x\", \"y\", \"z\"]].to_csv(f\"{inDir}/cifPointClouds/{a}/{fName[:-3]}csv\", index=False)\n",
    "        except:\n",
    "            print(f\"error with atom lab {a} in {fName} !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store atomic PDhash for xyz cords\n",
    "- unbound (all)\n",
    "- OverlapCO2\n",
    "    - bound vs unbound\n",
    "## TO-DO: John's predictions as well\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Way later on, this data will also be useful for building a transformer model that tries to predict DFT topology from point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDhash():\n",
    "    def __init__(self,res=1,diags=None, maxHdim=2,persistThresh=0):\n",
    "        \"\"\"upper bound resolution.\n",
    "        In the case of sparce PD spaces, it may be useful to project a hash map of your dataset to the diagram space\"\"\"\n",
    "        self.res=res\n",
    "        self.maxD=maxHdim\n",
    "        self.thresh=persistThresh\n",
    "        self.bounds=[[np.inf,-np.inf] for b in range(maxHdim+1)]\n",
    "        self.img={b:dict() for b in range(maxHdim+1)} # While this does impose extra time compared to np, it is ideal for map-reduce type parallelization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def addDiagRpp(self,diag,index): ## note the index can be just an index number, or a numerical value\n",
    "                                    ###although the numerical values (duplicate index) won't stack in the set\n",
    "        \"\"\"diag is {0:[(b,d),...],1: \"\"\"\n",
    "        for i in range(np.min([self.maxD+1,len(diag)])):\n",
    "            for k in diag[i]:\n",
    "                if k[1]-k[0] >self.thresh:\n",
    "                    pt=(round(k[0]/self.res)*self.res,round(k[1]/self.res)*self.res)\n",
    "                    if pt[0]<self.bounds[i][0]:\n",
    "                        self.bounds[i][0]=pt[0]\n",
    "                    if pt[1]>self.bounds[i][1]:\n",
    "                        self.bounds[i][1]=pt[1]\n",
    "                    if pt in self.img[i]:\n",
    "                        if index in self.img[i][pt]:\n",
    "                            self.img[i][pt][index]+=1\n",
    "                        else:\n",
    "                            self.img[i][pt][index]=1\n",
    "\n",
    "                    else:\n",
    "                        self.img[i][pt]={index:1}\n",
    "\n",
    "    def addDiagCubeRips(self,crispy,index):\n",
    "        \"\"\"diag is [[bi,b,d,bx,by,bz,dx,dy,dz],..] \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if type(item)==int:\n",
    "            return self.img[item]\n",
    "        else:\n",
    "            #return {b:self.img[b][pt] for b in range(self.maxD) for pt in self.img[b].keys()}\n",
    "            return {b:self.img[b][tuple(item)] for b in range(self.maxD) if tuple(item) in self.img[b]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mofNames=list(df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### all\n",
    "saveDir='diverseTopPDhash'\n",
    "failMOFs=set()\n",
    "pdStack=PDhash(res=.25,diags=None, maxHdim=2,persistThresh=0)\n",
    "for i in range(10):#len(mofNames)):\n",
    "    fName=mofNames[i]\n",
    "    cif_name = f\"{inDir}/cifs/{fName}.cif\"\n",
    "    try:\n",
    "        struct=Structure.from_file(cif_name)\n",
    "        rppdgm=rpp.run(\"--format distance --dim 2\",struct.distance_matrix)\n",
    "        npdgm=[np.array([[float(rppdgm[b][k][0]),float(rppdgm[b][k][1])] for k in range(len(rppdgm[b]))])for b in rppdgm.keys()]\n",
    "        pdStack.addDiagRpp(npdgm,i)\n",
    "    except:\n",
    "        failMOFs.add(fName)\n",
    "\n",
    "## next do same thing for the boundCO2 files and store them seperately\n",
    "### then filter out the unbound from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "topType=\"rppCords0_freq_QuartRes\"\n",
    "with open(f\"{inDir}/diverseTopPDhash/pdStack_{topType}.pkl\",\"wb\") as f:\n",
    "    pickle.dump(pdStackRpp,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failMOFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm(X,Y):\n",
    "    x2 = np.sum(X**2, axis=1)\n",
    "    y2 = np.sum(Y**2, axis=1)\n",
    "    xy=np.matmul(X,Y.T)\n",
    "    return x2.reshape(-1,1) - 2*xy + y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=atom_df.loc[:, [\"x\", \"y\", \"z\"]].to_numpy()\n",
    "X\n",
    "dm(X,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cif_xyz(fname): \n",
    "    cif_str = None\n",
    "    with io.open(fname, \"r\", newline=\"\\n\") as cif:\n",
    "        cif_str = cif.read().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    cif_list = cif_str.split(\"loop_\")\n",
    "    for cif_section in cif_list:\n",
    "        if \"_atom_site_fract_x\" in cif_section:\n",
    "            #atom_lines = cif_section.split(\"\\n\")\n",
    "            columns = list(re.findall(r\".*_atom_.*\\n\", cif_section))\n",
    "            df_str = cif_section.replace(\"\".join(columns), \"\").strip()\n",
    "            columns = [x.strip() for x in columns]\n",
    "            return pd.read_csv(io.StringIO(df_str), names=columns, sep=r\"\\s+\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Do CO2 bound and compare results \n",
    "- john version and ottawa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct=Structure.from_file(cif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir='diverseTopPDhash'\n",
    "failMOFs=set()\n",
    "pdStack2=PDhash(res=.25,diags=None, maxHdim=2,persistThresh=0)\n",
    "for i in range(100):#len(mofNames)):\n",
    "    fName=mofNames[i]\n",
    "    cif_name = f\"{inDir}/cifs/{fName}.cif\"\n",
    "    \n",
    "    try:\n",
    "        atom_df = grabAtomDF(cif_name)\n",
    "        X=atom_df.loc[:, [\"x\", \"y\", \"z\"]].to_numpy()\n",
    "        rppdgm=rpp.run(\"--format distance --dim 2\",dm(X,X))\n",
    "        npdgm=[np.array([[float(rppdgm[b][k][0]),float(rppdgm[b][k][1])] for k in range(len(rppdgm[b]))])for b in rppdgm.keys()]\n",
    "        pdStack2.addDiagRpp(npdgm,i)\n",
    "    except:\n",
    "        failMOFs.add(fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failMOFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npdgm=[np.array([[float(rppdgm[b][k][0]),float(rppdgm[b][k][1])] for k in range(len(rppdgm[b]))])for b in rppdgm.keys()]\n",
    "persim.plot_diagrams(npdgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdStack=PDhash(res=1,diags=None, maxHdim=2,persistThresh=0)\n",
    "pdStack.addDiagRpp(npdgm,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = gudhi.AlphaComplex(dat)\n",
    "st=ac.create_simplex_tree()\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genAlphaSlider(dat,initial=1,step=1,maximum=10,titlePrefix=\"\"): #assume 3D for now\n",
    "    ac = gudhi.AlphaComplex(dat)\n",
    "    st = ac.create_simplex_tree()\n",
    "    skel=list(st.get_skeleton(2))\n",
    "    skel.sort(key=lambda s: s[1])\n",
    "    points = np.array([ac.get_point(i) for i in range(st.num_vertices())])\n",
    "    #lims=[[np.floor(np.min(dat[:,i])),np.ceil(np.max(dat[:,i]))] for i in range(3)]\n",
    "    alpha = widgets.FloatSlider(\n",
    "        value = initial,\n",
    "        min = 0.0,\n",
    "        max = maximum,\n",
    "        step = step,\n",
    "        description = 'Alpha:',\n",
    "        readout_format = '.4f'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    b1s=np.array([s[0] for s in skel if len(s[0]) == 2 and s[1] <= alpha.value])\n",
    "    triangles = np.array([s[0] for s in skel if len(s[0]) == 3 and s[1] <= alpha.value])\n",
    "\n",
    "\n",
    "    pts=go.Scatter3d(\n",
    "        x = points[:, 0],\n",
    "        y = points[:, 1],\n",
    "        z = points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=\"cornflowerblue\",                # set color to an array/list of desired values\n",
    "            #colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=.9\n",
    "        ),\n",
    "        name='H0'\n",
    "\n",
    "    )\n",
    "\n",
    "    sfig=[pts]\n",
    "\n",
    "    linepts={0:[],1:[],2:[]}\n",
    "    for i in b1s:\n",
    "        linepts[0].append(points[i[0],0])\n",
    "        linepts[1].append(points[i[0],1])\n",
    "        linepts[2].append(points[i[0],2])\n",
    "        linepts[0].append(points[i[1],0])\n",
    "        linepts[1].append(points[i[1],1])\n",
    "        linepts[2].append(points[i[1],2])\n",
    "\n",
    "        linepts[0].append(None)\n",
    "        linepts[1].append(None)\n",
    "        linepts[2].append(None)\n",
    "\n",
    "    if len(linepts[0])>0:\n",
    "        lins=go.Scatter3d(\n",
    "            x=linepts[0],\n",
    "            y=linepts[1],\n",
    "            z=linepts[2],\n",
    "            mode='lines',\n",
    "            name='H1',\n",
    "            marker=dict(\n",
    "                size=3,\n",
    "                color=\"#d55e00\",                # set color to an array/list of desired values\n",
    "                #colorscale='Viridis',   # choose a colorscale\n",
    "                opacity=.9\n",
    "            )\n",
    "        )\n",
    "        sfig.append(lins)\n",
    "        if len(triangles)>0:\n",
    "            mesh = go.Mesh3d(\n",
    "                x = points[:, 0],\n",
    "                y = points[:, 1],\n",
    "                z = points[:, 2],\n",
    "                i = triangles[:, 0],\n",
    "                j = triangles[:, 1],\n",
    "                k = triangles[:, 2],\n",
    "                color=\"#009e73\",\n",
    "                opacity=.75,\n",
    "                name='H2'\n",
    "            )\n",
    "\n",
    "\n",
    "            sfig.append(mesh)\n",
    "    fig=go.Figure(sfig)\n",
    "    fig.update_layout(width=800,height=800)\n",
    "    #fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def view_SC(alpha):\n",
    "        if alpha==0:\n",
    "            fig=go.Figure(sfig[0])\n",
    "            fig.show()\n",
    "        else:\n",
    "            b1s=np.array([s[0] for s in skel if len(s[0]) == 2 and s[1] <= alpha])\n",
    "\n",
    "            linepts={0:[],1:[],2:[]}\n",
    "            for i in b1s:\n",
    "                linepts[0].append(points[i[0],0])\n",
    "                linepts[1].append(points[i[0],1])\n",
    "                linepts[2].append(points[i[0],2])\n",
    "                linepts[0].append(points[i[1],0])\n",
    "                linepts[1].append(points[i[1],1])\n",
    "                linepts[2].append(points[i[1],2])\n",
    "\n",
    "                linepts[0].append(None)\n",
    "                linepts[1].append(None)\n",
    "                linepts[2].append(None)\n",
    "\n",
    "            if len(linepts[0])>0:\n",
    "                lins=go.Scatter3d(\n",
    "                    x=linepts[0],\n",
    "                    y=linepts[1],\n",
    "                    z=linepts[2],\n",
    "                    mode='lines',\n",
    "                    name='H1',\n",
    "                    marker=dict(\n",
    "                        size=3,\n",
    "                        color=\"#d55e00\",                # set color to an array/list of desired values\n",
    "                        #colorscale='Viridis',   # choose a colorscale\n",
    "                        opacity=.85\n",
    "                    )\n",
    "                )\n",
    "                if len(sfig)>1:\n",
    "                    sfig[1]=lins\n",
    "                else:\n",
    "                    sfig.append(lins)\n",
    "                triangles = np.array([s[0] for s in skel if len(s[0]) == 3 and s[1] <= alpha])\n",
    "                if len(triangles)>0:\n",
    "                    mesh = go.Mesh3d(\n",
    "                        x = points[:, 0],\n",
    "                        y = points[:, 1],\n",
    "                        z = points[:, 2],\n",
    "                        i = triangles[:, 0],\n",
    "                        j = triangles[:, 1],\n",
    "                        k = triangles[:, 2],\n",
    "                        color=\"#009e73\",\n",
    "                        opacity=.5,\n",
    "                        name='H2'\n",
    "                    )\n",
    "\n",
    "                    if len(sfig)>2:\n",
    "                        sfig[2]=mesh\n",
    "                    else:\n",
    "                        sfig.append(mesh)\n",
    "\n",
    "\n",
    "            fig=go.Figure(data=sfig,layout=go.Layout(width=800,height=800,\n",
    "                                                     title=f\"{titlePrefix}:\\nSimplicial complex with radius <= {round(float(alpha),5)}\",\n",
    "                                                    ))\n",
    "\n",
    "            #fig.show()\n",
    "            iplot(fig)\n",
    "\n",
    "\n",
    "    widgets.interact(view_SC, alpha = alpha);\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=bestMOF+\".cif\"\n",
    "tittxt=f\"{fName[:-4]} AllAtoms \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=worstMOF+\".cif\"\n",
    "tittxt=f\"{fName[:-4]} AllAtoms \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB12-VEHNED_clean.cif\"\n",
    "tittxt=f\"{fName[:-4]} AllAtoms \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fName=\"DB1-Zn2O8-fum_A-irmof20_A_No142.cif\"\n",
    "tittxt=f\"{fName[:-4]} AllAtoms \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB12-CUVGIK_clean.cif\"\n",
    "tittxt=f\"{fName[:-4]} Nitrogen Topology \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/N/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB12-CUVGIK_clean.cif\"\n",
    "tittxt=f\"{fName[:-4]} Carbon Topology \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/C/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB0-m2_o13_o27_f0_pcu.sym.114.cif\"\n",
    "tittxt=f\"bad MOF: {fName[:-4]} All Atoms Topology \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB12-VEHNED_clean.cif\"\n",
    "tittxt=f\"bad MOF: {fName[:-4]} All Atoms Topology \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB0-m2_o13_o27_f0_pcu.sym.114.cif\"\n",
    "tittxt=f\"bad MOF: {fName[:-4]} Carbon Topology \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/C/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName=\"DB12-BEXSEE_clean.cif\"\n",
    "tittxt=f\"highCap MOF: {fName[:-4]} AllAtoms Topology \"\n",
    "dat=np.genfromtxt(f\"{inDir}/cifPointClouds/total/{fName[:-3]}csv\", dtype=float, delimiter=',', names=True)\n",
    "st=genAlphaSlider(dat,titlePrefix=tittxt,step=.5)\n",
    "dgm=st.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gudhi.plot_persistence_diagram(dgm, legend = True)\n",
    "plt.title(tittxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagrams(\n",
    "    diagrams,\n",
    "    plot_only=None,\n",
    "    title=None,\n",
    "    xy_range=None,\n",
    "    labels=None,\n",
    "    colormap=\"default\",\n",
    "    size=20,\n",
    "    ax_color=np.array([0.0, 0.0, 0.0]),\n",
    "    diagonal=True,\n",
    "    lifetime=False,\n",
    "    legend=True,\n",
    "    show=False,\n",
    "    ax=None,\n",
    "    saveLoc=None\n",
    "):\n",
    "    \"\"\"A helper function to plot persistence diagrams.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    diagrams: ndarray (n_pairs, 2) or list of diagrams\n",
    "        A diagram or list of diagrams. If diagram is a list of diagrams,\n",
    "        then plot all on the same plot using different colors.\n",
    "    plot_only: list of numeric\n",
    "        If specified, an array of only the diagrams that should be plotted.\n",
    "    title: string, default is None\n",
    "        If title is defined, add it as title of the plot.\n",
    "    xy_range: list of numeric [xmin, xmax, ymin, ymax]\n",
    "        User provided range of axes. This is useful for comparing\n",
    "        multiple persistence diagrams.\n",
    "    labels: string or list of strings\n",
    "        Legend labels for each diagram.\n",
    "        If none are specified, we use H_0, H_1, H_2,... by default.\n",
    "    colormap: string, default is 'default'\n",
    "        Any of matplotlib color palettes.\n",
    "        Some options are 'default', 'seaborn', 'sequential'.\n",
    "        See all available styles with\n",
    "\n",
    "        .. code:: python\n",
    "\n",
    "            import matplotlib as mpl\n",
    "            print(mpl.styles.available)\n",
    "\n",
    "    size: numeric, default is 20\n",
    "        Pixel size of each point plotted.\n",
    "    ax_color: any valid matplotlib color type.\n",
    "        See [https://matplotlib.org/api/colors_api.html](https://matplotlib.org/api/colors_api.html) for complete API.\n",
    "    diagonal: bool, default is True\n",
    "        Plot the diagonal x=y line.\n",
    "    lifetime: bool, default is False. If True, diagonal is turned to False.\n",
    "        Plot life time of each point instead of birth and death.\n",
    "        Essentially, visualize (x, y-x).\n",
    "    legend: bool, default is True\n",
    "        If true, show the legend.\n",
    "    show: bool, default is False\n",
    "        Call plt.show() after plotting. If you are using self.plot() as part\n",
    "        of a subplot, set show=False and call plt.show() only once at the end.\n",
    "    \"\"\"\n",
    "\n",
    "    ax = ax or plt.gca()\n",
    "    plt.style.use(colormap)\n",
    "\n",
    "    xlabel, ylabel = \"Birth\", \"Death\"\n",
    "\n",
    "    if not isinstance(diagrams, list):\n",
    "        # Must have diagrams as a list for processing downstream\n",
    "        diagrams = [diagrams]\n",
    "\n",
    "    if labels is None:\n",
    "        # Provide default labels for diagrams if using self.dgm_\n",
    "        labels = [\"$H_{{{}}}$\".format(i) for i , _ in enumerate(diagrams)]\n",
    "\n",
    "    if plot_only:\n",
    "        diagrams = [diagrams[i] for i in plot_only]\n",
    "        labels = [labels[i] for i in plot_only]\n",
    "\n",
    "    if not isinstance(labels, list):\n",
    "        labels = [labels] * len(diagrams)\n",
    "\n",
    "    # Construct copy with proper type of each diagram\n",
    "    # so we can freely edit them.\n",
    "    diagrams = [dgm.astype(np.float32, copy=True) for dgm in diagrams]\n",
    "\n",
    "    # find min and max of all visible diagrams\n",
    "    concat_dgms = np.concatenate(diagrams).flatten()\n",
    "    has_inf = np.any(np.isinf(concat_dgms))\n",
    "    finite_dgms = concat_dgms[np.isfinite(concat_dgms)]\n",
    "\n",
    "    # clever bounding boxes of the diagram\n",
    "    if not xy_range:\n",
    "        # define bounds of diagram\n",
    "        ax_min, ax_max = np.min(finite_dgms), np.max(finite_dgms)\n",
    "        x_r = ax_max - ax_min\n",
    "\n",
    "        # Give plot a nice buffer on all sides.\n",
    "        # ax_range=0 when only one point,\n",
    "        buffer = 1 if xy_range == 0 else x_r / 5\n",
    "\n",
    "        x_down = ax_min - buffer / 2\n",
    "        x_up = ax_max + buffer\n",
    "\n",
    "        y_down, y_up = x_down, x_up\n",
    "    else:\n",
    "        x_down, x_up, y_down, y_up = xy_range\n",
    "\n",
    "    yr = y_up - y_down\n",
    "\n",
    "    if lifetime:\n",
    "\n",
    "        # Don't plot landscape and diagonal at the same time.\n",
    "        diagonal = False\n",
    "\n",
    "        # reset y axis so it doesn't go much below zero\n",
    "        y_down = -yr * 0.05\n",
    "        y_up = y_down + yr\n",
    "\n",
    "        # set custom ylabel\n",
    "        ylabel = \"Lifetime\"\n",
    "\n",
    "        # set diagrams to be (x, y-x)\n",
    "        for dgm in diagrams:\n",
    "            dgm[:, 1] -= dgm[:, 0]\n",
    "\n",
    "        # plot horizon line\n",
    "        ax.plot([x_down, x_up], [0, 0], c=ax_color)\n",
    "\n",
    "    # Plot diagonal\n",
    "    if diagonal:\n",
    "        ax.plot([x_down, x_up], [x_down, x_up], \"--\", c=ax_color)\n",
    "\n",
    "    # Plot inf line\n",
    "    if has_inf:\n",
    "        # put inf line slightly below top\n",
    "        b_inf = y_down + yr * 0.95\n",
    "        ax.plot([x_down, x_up], [b_inf, b_inf], \"--\", c=\"k\", label=r\"$\\infty$\")\n",
    "\n",
    "        # convert each inf in each diagram with b_inf\n",
    "        for dgm in diagrams:\n",
    "            dgm[np.isinf(dgm)] = b_inf\n",
    "\n",
    "    # Plot each diagram\n",
    "    for dgm, label in zip(diagrams, labels):\n",
    "\n",
    "        # plot persistence pairs\n",
    "        ax.scatter(dgm[:, 0], dgm[:, 1], size, label=label, edgecolor=\"none\")\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    ax.set_xlim([x_down, x_up])\n",
    "    ax.set_ylim([y_down, y_up])\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    if legend is True:\n",
    "        ax.legend(loc=\"lower right\")\n",
    "\n",
    "    if saveLoc and type(saveLoc)==str:\n",
    "        #ax.set_title(saveLoc[len(saveLoc)-saveLoc[::-1].find(\"\\\\\")::saveLoc.find(\".\")] + ' espDist')\n",
    "        plt.savefig(f'{saveLoc}',dpi=300,bbox_inches='tight')\n",
    "\n",
    "    if show is True:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
